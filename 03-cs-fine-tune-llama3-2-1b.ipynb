{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2a2b896-7de6-4abe-a85c-d7f46203d74c",
   "metadata": {},
   "source": [
    "### Set the variables for base model, dataset, and new model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34bc623d-0150-4ffa-8923-4d8e2d8ef343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (2.3.1)\n",
      "Requirement already satisfied: matplotlib in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (3.10.3)\n",
      "Requirement already satisfied: seaborn in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (0.13.2)\n",
      "Requirement already satisfied: fsspec in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (2025.3.0)\n",
      "Requirement already satisfied: huggingface_hub in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (0.34.1)\n",
      "Requirement already satisfied: textblob in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (0.19.0)\n",
      "Requirement already satisfied: torch in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (2.7.1)\n",
      "Requirement already satisfied: transformers in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (4.54.0)\n",
      "Requirement already satisfied: datasets in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from -r requirements.txt (line 14)) (4.0.0)\n",
      "Requirement already satisfied: accelerate in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from -r requirements.txt (line 15)) (1.9.0)\n",
      "Requirement already satisfied: peft in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from -r requirements.txt (line 16)) (0.16.0)\n",
      "Requirement already satisfied: trl in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from -r requirements.txt (line 17)) (0.19.1)\n",
      "Requirement already satisfied: bitsandbytes in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from -r requirements.txt (line 18)) (0.46.1)\n",
      "Requirement already satisfied: wandb in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from -r requirements.txt (line 19)) (0.21.0)\n",
      "Requirement already satisfied: kubernetes in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from -r requirements.txt (line 22)) (33.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 2)) (2025.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 2)) (2025.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 2)) (2.2.6)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 3)) (4.59.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 3)) (25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 3)) (1.4.8)\n",
      "Requirement already satisfied: cycler>=0.10 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 3)) (0.12.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 3)) (1.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 3)) (3.1.4)\n",
      "Requirement already satisfied: pillow>=8 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 3)) (11.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from huggingface_hub->-r requirements.txt (line 7)) (6.0.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->-r requirements.txt (line 7)) (3.18.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from huggingface_hub->-r requirements.txt (line 7)) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from huggingface_hub->-r requirements.txt (line 7)) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from huggingface_hub->-r requirements.txt (line 7)) (1.1.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->-r requirements.txt (line 7)) (2.32.4)\n",
      "Requirement already satisfied: nltk>=3.9 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from textblob->-r requirements.txt (line 8)) (3.9.1)\n",
      "Requirement already satisfied: networkx in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->-r requirements.txt (line 11)) (3.4.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->-r requirements.txt (line 11)) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->-r requirements.txt (line 11)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->-r requirements.txt (line 11)) (11.7.1.2)\n",
      "Requirement already satisfied: jinja2 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->-r requirements.txt (line 11)) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->-r requirements.txt (line 11)) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->-r requirements.txt (line 11)) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->-r requirements.txt (line 11)) (12.6.77)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->-r requirements.txt (line 11)) (1.14.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->-r requirements.txt (line 11)) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->-r requirements.txt (line 11)) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->-r requirements.txt (line 11)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->-r requirements.txt (line 11)) (0.6.3)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->-r requirements.txt (line 11)) (1.11.1.6)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->-r requirements.txt (line 11)) (2.26.2)\n",
      "Requirement already satisfied: triton==3.3.1 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->-r requirements.txt (line 11)) (3.3.1)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->-r requirements.txt (line 11)) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from torch->-r requirements.txt (line 11)) (12.6.80)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from triton==3.3.1->torch->-r requirements.txt (line 11)) (80.9.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 13)) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 13)) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 13)) (0.5.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 14)) (21.0.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 14)) (0.70.16)\n",
      "Requirement already satisfied: xxhash in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 14)) (3.5.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 14)) (0.3.8)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 15)) (5.9.8)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 19)) (4.25.8)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 19)) (2.33.2)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 19)) (4.3.8)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 19)) (8.2.1)\n",
      "Requirement already satisfied: pydantic<3 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 19)) (2.11.7)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 19)) (3.1.45)\n",
      "Requirement already satisfied: six>=1.9.0 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from kubernetes->-r requirements.txt (line 22)) (1.17.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from kubernetes->-r requirements.txt (line 22)) (2.40.3)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from kubernetes->-r requirements.txt (line 22)) (1.8.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from kubernetes->-r requirements.txt (line 22)) (3.3.1)\n",
      "Requirement already satisfied: durationpy>=0.7 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from kubernetes->-r requirements.txt (line 22)) (0.10)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes->-r requirements.txt (line 22)) (2.5.0)\n",
      "Requirement already satisfied: requests-oauthlib in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from kubernetes->-r requirements.txt (line 22)) (2.0.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.10/dist-packages (from kubernetes->-r requirements.txt (line 22)) (2025.7.14)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from fsspec->-r requirements.txt (line 6)) (3.12.14)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 19)) (4.0.12)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes->-r requirements.txt (line 22)) (5.5.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes->-r requirements.txt (line 22)) (4.9.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes->-r requirements.txt (line 22)) (0.4.2)\n",
      "Requirement already satisfied: joblib in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from nltk>=3.9->textblob->-r requirements.txt (line 8)) (1.5.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from pydantic<3->wandb->-r requirements.txt (line 19)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from pydantic<3->wandb->-r requirements.txt (line 19)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from pydantic<3->wandb->-r requirements.txt (line 19)) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->-r requirements.txt (line 7)) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->-r requirements.txt (line 7)) (3.10)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 11)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from jinja2->torch->-r requirements.txt (line 11)) (3.0.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->-r requirements.txt (line 6)) (0.3.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->-r requirements.txt (line 6)) (2.6.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->-r requirements.txt (line 6)) (1.20.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->-r requirements.txt (line 6)) (25.3.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->-r requirements.txt (line 6)) (5.0.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->-r requirements.txt (line 6)) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->-r requirements.txt (line 6)) (6.6.3)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->-r requirements.txt (line 6)) (1.4.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 19)) (5.0.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /root/.clearml/venvs-builds/3.10/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes->-r requirements.txt (line 22)) (0.6.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8e9ac95-70b6-4ffe-9694-0a2132266d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_loc = \"output/checkpoints\"\n",
    "lora_adapter_loc = \"output/lora_adapter\"\n",
    "#dataset_name = \"bitext/Bitext-customer-support-llm-chatbot-training-dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b834150-1f0a-491b-809b-f1082af0779d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CLEARML_LOG_MODEL=True\n",
      "2025-07-26 03:54:52,962 - clearml - WARNING - InsecureRequestWarning: Certificate verification is disabled! Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "ClearML Task: created new task id=4f13e3616926496281180d1f83ddfa6a\n",
      "2025-07-26 03:54:53,562 - clearml.Task - INFO - Storing jupyter notebook directly as code\n",
      "ClearML results page: https://app.clearml.bizilife.net/projects/d4b25b0d2de64d6bb07fbca370f0439e/experiments/4f13e3616926496281180d1f83ddfa6a/output/log\n"
     ]
    }
   ],
   "source": [
    "%env CLEARML_LOG_MODEL=True\n",
    "from clearml import Task, OutputModel, Dataset\n",
    "\n",
    "project_name = 'cnasg-tk/CustomerSupport'\n",
    "task_name = \"03-fine-tune-llama3-2-1b\"\n",
    "s3_base_bucket_loc = 's3://tk-aip/clearml'\n",
    "base_model = \"/mnt/shared/models/huggingface/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "task = Task.init(project_name=project_name, task_name=task_name, output_uri=s3_base_bucket_loc)\n",
    "#Task.add_requirements(\"./requirements.txt\")\n",
    "#task.set_parameter(\"base-model\",base_model)\n",
    "#task.set_parameter(\"lora-adapter\",task_name)\n",
    "#task.set_base_docker(docker_image=\"nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04\")\n",
    "##task.set_base_docker(docker_image=\"nvidia/cuda:12.4.1-cudnn-runtime-ubuntu22.04\")\n",
    "#task.execute_remotely(queue_name=\"q-group-a-gpu-10gb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0c3383-f7b9-4ec2-9b76-716e0018c984",
   "metadata": {},
   "source": [
    "### Load the Python packages and functions we will use throughout the fine-tuning and evaluation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cec051a7-9617-405e-95b1-b6470858dfea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/dummy/dummy/runs/t4zj72mi?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7d21ad82ca00>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftModel,\n",
    "    prepare_model_for_kbit_training,\n",
    "    get_peft_model,\n",
    ")\n",
    "import os, torch, wandb\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer, setup_chat_format\n",
    "\n",
    "wandb.init(mode=\"disabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f54975-0315-46e2-903c-73f3a61d9247",
   "metadata": {},
   "source": [
    "## 2. Loading the model and tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492aff83-e30f-4d10-a129-56b6a314febb",
   "metadata": {},
   "source": [
    "### Set the data type and attention implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5ca092f-7c00-4352-907f-78e62631e9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set torch dtype and attention implementation\n",
    "#if torch.cuda.get_device_capability()[0] >= 8:\n",
    "#    print(\"install flash-attn!!!\")\n",
    "##    !pip install -qqq flash-attn\n",
    "##    !pip install flash-attn --no-build-isolation\n",
    "#    torch_dtype = torch.bfloat16\n",
    "#    attn_implementation = \"flash_attention_2\"\n",
    "#else:\n",
    "#    torch_dtype = torch.float16\n",
    "#    attn_implementation = \"eager\"\n",
    "\n",
    "torch_dtype = torch.float16\n",
    "attn_implementation = \"eager\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6ae918-58d5-4bd9-be07-0342882a134d",
   "metadata": {},
   "source": [
    "### Load the model and tokenizer by providing the local model directory, we will load the model in 4-bit quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49e7e369-663c-48a1-8693-bfcb5616b899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QLoRA config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch_dtype,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "# Load model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=attn_implementation\n",
    ")\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ded953b-4658-4e9f-a8e8-86e010dd174d",
   "metadata": {},
   "source": [
    "## 3. Loading and processing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55c72a6a-901d-4421-83fb-5770e9d93633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-26 03:55:02,708 - clearml - INFO - Dataset.get() did not specify alias. Dataset information will not be automatically logged in ClearML Server.\n",
      "2025-07-26 03:55:02,881 - clearml - WARNING - InsecureRequestWarning: Certificate verification is disabled! Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n"
     ]
    }
   ],
   "source": [
    "cml_dataset_project = \"cnasg-tk/CustomerSupport\"\n",
    "cml_dataset_name = \"bitext-customer-support\"\n",
    "cml_dataset = Dataset.get(\n",
    "        dataset_project=cml_dataset_project,\n",
    "        dataset_name=cml_dataset_name,\n",
    "        only_completed=True,\n",
    "        only_published=False,\n",
    ")\n",
    "dataset_path = cml_dataset.get_local_copy()\n",
    "files = cml_dataset.list_files()\n",
    "data_file = dataset_path + \"/\" + files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8940615-1e15-428b-8c9a-d2e53878b1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the dataset\n",
    "#dataset = load_dataset(dataset_name, split=\"train\")\n",
    "dataset = load_dataset(\"csv\", data_files=data_file, split=\"train\")\n",
    "dataset = dataset.shuffle(seed=65).select(range(1000)) # Only use 1000 samples for quick demo\n",
    "instruction = \"\"\"You are a top-rated customer service agent named John. \n",
    "    Be polite to customers and answer all their questions.\n",
    "    \"\"\"\n",
    "def format_chat_template(row):\n",
    "    \n",
    "    row_json = [{\"role\": \"system\", \"content\": instruction },\n",
    "               {\"role\": \"user\", \"content\": row[\"instruction\"]},\n",
    "               {\"role\": \"assistant\", \"content\": row[\"response\"]}]\n",
    "    \n",
    "    row[\"text\"] = tokenizer.apply_chat_template(row_json, tokenize=False)\n",
    "    return row\n",
    "\n",
    "dataset = dataset.map(\n",
    "    format_chat_template,\n",
    "    num_proc= 4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97faa27a-cee6-4b44-bda9-e752eeb3b449",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['text'][3]\n",
    "dataset = dataset.train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055fb533-6b1e-44d3-93ad-7616e957ba55",
   "metadata": {},
   "source": [
    "## 4. Setting up the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b3e438-4d99-4a2b-b487-95a05aef4680",
   "metadata": {},
   "source": [
    "### Extract the linear model name from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9ca6a4a-5dd4-4388-95a8-bb7e534711bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bitsandbytes as bnb\n",
    "\n",
    "def find_all_linear_names(model):\n",
    "    cls = bnb.nn.Linear4bit\n",
    "    lora_module_names = set()\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, cls):\n",
    "            names = name.split('.')\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "    if 'lm_head' in lora_module_names:  # needed for 16 bit\n",
    "        lora_module_names.remove('lm_head')\n",
    "    return list(lora_module_names)\n",
    "\n",
    "modules = find_all_linear_names(model)\n",
    "#modules = ['gate_proj', 'v_proj', 'up_proj', 'q_proj', 'down_proj', 'k_proj', 'o_proj']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d570be8-986a-4795-a5b2-3d2641f18fba",
   "metadata": {},
   "source": [
    "### Use the linear module name to create the LoRA adopter. We will only fine-tune the LoRA adopter and leave the rest of the model to save memory and for faster training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e582a89-2f36-487f-9f5b-ce73c30431fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA config\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=modules\n",
    ")\n",
    "#model, tokenizer = setup_chat_format(model, tokenizer)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc54d4e2-b769-4f2e-9bc8-238c0409bbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparamter\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=checkpoint_loc,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=2,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    num_train_epochs=1,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=0.2,\n",
    "    logging_steps=1,\n",
    "    warmup_steps=10,\n",
    "    logging_strategy=\"steps\",\n",
    "    learning_rate=2e-4,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    group_by_length=True,\n",
    "#    report_to=\"wandb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83de896a-6b38-4c0b-8d04-66507b7a5e43",
   "metadata": {},
   "source": [
    "### We will now set up a supervised fine-tuning (SFT) trainer and provide a train and evaluation dataset, LoRA configuration, training argument, tokenizer, and model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "721daa56-64b1-4eaf-a858-231c36a6a6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "# Setting sft parameters\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    peft_config=peft_config,\n",
    "#    max_seq_length= 512,\n",
    "#    dataset_text_field=\"text\",\n",
    "#    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "#    packing= False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f55aa4-76d3-4f55-907a-8753d120e425",
   "metadata": {},
   "source": [
    "## 5. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f601193-f826-4556-9c0f-0fd6a52fb841",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-26 03:55:05,132 - clearml.Task - WARNING - Parameters must be of builtin type (Transformers/accelerator_config[AcceleratorConfig])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='450' max='450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [450/450 03:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.814600</td>\n",
       "      <td>0.835515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.897600</td>\n",
       "      <td>0.744222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.703900</td>\n",
       "      <td>0.699311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.595800</td>\n",
       "      <td>0.669215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.536900</td>\n",
       "      <td>0.646707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-26 03:57:36,108 - clearml.storage - INFO - Starting upload: /tmp/.clearml.upload_model_z_u3ft_z.tmp => tk-aip/clearml/cnasg-tk/CustomerSupport/03-fine-tune-llama3-2-1b.4f13e3616926496281180d1f83ddfa6a/models/training_args.bin\n",
      "2025-07-26 03:57:36,358 - clearml.Task - INFO - Completed model upload to s3://tk-aip/clearml/cnasg-tk/CustomerSupport/03-fine-tune-llama3-2-1b.4f13e3616926496281180d1f83ddfa6a/models/training_args.bin\n",
      "2025-07-26 03:57:36,774 - clearml.storage - INFO - Starting upload: /tmp/.clearml.upload_model_sk8q64k8.tmp => tk-aip/clearml/cnasg-tk/CustomerSupport/03-fine-tune-llama3-2-1b.4f13e3616926496281180d1f83ddfa6a/models/optimizer.pt\n",
      "2025-07-26 03:57:36,943 - clearml.storage - INFO - Uploading: 86.13MB from /tmp/.clearml.upload_model_sk8q64k8.tmp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           0% | 0.00/86.13 MB [00:00<?, ?MB/s]: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-26 03:57:37,608 - clearml.Task - INFO - Waiting for previous model to upload (2 pending, s3://tk-aip/clearml/cnasg-tk/CustomerSupport/03-fine-tune-llama3-2-1b.4f13e3616926496281180d1f83ddfa6a/models/rng_state.pth)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "███████████████████████████████ 100% | 86.13/86.13 MB [00:01<00:00, 44.08MB/s]: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-26 03:57:38,905 - clearml.Task - INFO - Completed model upload to s3://tk-aip/clearml/cnasg-tk/CustomerSupport/03-fine-tune-llama3-2-1b.4f13e3616926496281180d1f83ddfa6a/models/optimizer.pt\n",
      "2025-07-26 03:57:39,025 - clearml.storage - INFO - Starting upload: /tmp/.clearml.upload_model_n13k5ro3.tmp => tk-aip/clearml/cnasg-tk/CustomerSupport/03-fine-tune-llama3-2-1b.4f13e3616926496281180d1f83ddfa6a/models/scheduler.pt\n",
      "2025-07-26 03:57:39,073 - clearml.Task - INFO - Completed model upload to s3://tk-aip/clearml/cnasg-tk/CustomerSupport/03-fine-tune-llama3-2-1b.4f13e3616926496281180d1f83ddfa6a/models/scheduler.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-26 03:57:39,190 - clearml.storage - INFO - Starting upload: /tmp/.clearml.upload_model_rho2dj49.tmp => tk-aip/clearml/cnasg-tk/CustomerSupport/03-fine-tune-llama3-2-1b.4f13e3616926496281180d1f83ddfa6a/models/rng_state.pth\n",
      "2025-07-26 03:57:39,237 - clearml.Task - INFO - Completed model upload to s3://tk-aip/clearml/cnasg-tk/CustomerSupport/03-fine-tune-llama3-2-1b.4f13e3616926496281180d1f83ddfa6a/models/rng_state.pth\n",
      "2025-07-26 03:58:08,497 - clearml.storage - INFO - Starting upload: /tmp/model_package.1mn0rary.zip => tk-aip/clearml/cnasg-tk/CustomerSupport/03-fine-tune-llama3-2-1b.4f13e3616926496281180d1f83ddfa6a/models/checkpoint-450.zip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=450, training_loss=0.7906042362584008, metrics={'train_runtime': 183.478, 'train_samples_per_second': 4.905, 'train_steps_per_second': 2.453, 'total_flos': 1052669993852928.0, 'train_loss': 0.7906042362584008})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-26 03:58:08,650 - clearml.storage - INFO - Uploading: 145.76MB from /tmp/model_package.1mn0rary.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "█████████████████████████████ 100% | 145.76/145.76 MB [00:02<00:00, 61.28MB/s]: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-26 03:58:11,033 - clearml.Task - INFO - Completed model upload to s3://tk-aip/clearml/cnasg-tk/CustomerSupport/03-fine-tune-llama3-2-1b.4f13e3616926496281180d1f83ddfa6a/models/checkpoint-450.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-26 03:58:16,280 - clearml.storage - INFO - Starting upload: /tmp/model_package.iq4_h09o.zip => tk-aip/clearml/cnasg-tk/CustomerSupport/03-fine-tune-llama3-2-1b.4f13e3616926496281180d1f83ddfa6a/models/remote_lora_adapter_zipped.zip\n",
      "2025-07-26 03:58:16,356 - clearml.storage - INFO - Uploading: 43.03MB from /tmp/model_package.iq4_h09o.zip\n",
      "2025-07-26 03:58:16,359 - clearml.storage - INFO - Uploading: 43.03MB from /tmp/model_package.iq4_h09o.zip\n",
      "2025-07-26 03:58:16,363 - clearml.storage - INFO - Uploading: 6.00MB / 43.03MB @ 77.56MBs from /tmp/model_package.iq4_h09o.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "█████████████████████████████▌   95% | 41.03/43.03 MB [00:00<00:00, 61.64MB/s]: \n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3c594c-3b07-4afd-b5bd-8cde56d98d7e",
   "metadata": {},
   "source": [
    "## 6. Model Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fdb429-6666-4865-b00b-ed16c070d633",
   "metadata": {},
   "source": [
    "### To test the fine-tuned model, we will provide it with the sample prompt from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f1103f1-5558-46db-b458-4ae30f3f43a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "I've taken note that you have bought the same item twice and would like to cancel order {{Order Number}}. I understand that this may have caused inconvenience, and I'm here to assist you in resolving this matter. To cancel your order, I recommend reaching out to our customer support team. They will be able to provide you with the necessary instructions and guidance to cancel your order successfully. In the meantime, I encourage you to review the terms and conditions of your purchase and contact our customer support if you have any questions or concerns. We value your satisfaction and are committed to resolving this issue for you.\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": instruction},\n",
    "    {\"role\": \"user\", \"content\": \"I bought the same item twice, cancel order {{Order Number}}\"}]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "inputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True).to(\"cuda\")\n",
    "outputs = model.generate(**inputs, max_new_tokens=150, num_return_sequences=1)\n",
    "text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(text.split(\"assistant\")[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdcfbf1-0fb7-4ec6-af78-7dfba707d7b5",
   "metadata": {},
   "source": [
    "## 7. Saving the tokenizer and model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bd5ec7-036a-4da0-9030-64b468c3d3a2",
   "metadata": {},
   "source": [
    "### Output LoRA Adapter to local folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49200aca-d34c-425c-b474-153ffb9a1e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(lora_adapter_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890e7c1e-ca9b-4a91-9f0f-6a816f12f2be",
   "metadata": {},
   "source": [
    "### Upload LoRA Adapter in Zipped format to S3 Bucket via ClearML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "896c3aa1-8a33-45d9-b12d-56c1ae71d93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-26 03:58:14,643 - clearml.storage - INFO - Uploading: 43.03MB from output/lora_adapter/adapter_model.safetensors\n",
      "2025-07-26 03:58:14,646 - clearml.storage - INFO - Uploading: 43.03MB from output/lora_adapter/adapter_model.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "██████████████████████████████▎  98% | 42.03/43.03 MB [00:00<00:00, 61.51MB/s]: \n"
     ]
    }
   ],
   "source": [
    "from clearml import Task, OutputModel, StorageManager\n",
    "\n",
    "s3_bucket_loc = s3_base_bucket_loc + \"/\" + Task.current_task().get_project_name() + \"/\" + task_name + \".\" + task.id + \"/models/lora_adapter\"\n",
    "StorageManager.upload_folder(lora_adapter_loc, s3_bucket_loc)\n",
    "clearmlModel = OutputModel(\n",
    "    task=Task.current_task(),\n",
    "    framework=\"PyTorch\",\n",
    "    name=\"remote_lora_adapter_loc\"\n",
    ")\n",
    "clearmlModel.update_weights(\n",
    "    register_uri=s3_bucket_loc,\n",
    "    target_filename = \"remote_lora_adapter_loc\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce1dcc71-f16f-43d0-960b-0882a2c2cd6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://tk-aip/clearml/cnasg-tk/CustomerSupport/03-fine-tune-llama3-2-1b.4f13e3616926496281180d1f83ddfa6a/models/remote_lora_adapter_zipped.zip'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lora_adapter = task_name\n",
    "\n",
    "#from clearml import Task, OutputModel\n",
    "# Upload the merged model to S3 bucket\n",
    "clearmlModel = OutputModel(\n",
    "    task=Task.current_task(),\n",
    "    framework=\"PyTorch\",\n",
    "    name=\"remote_lora_adapter_zipped\"\n",
    ")\n",
    "clearmlModel.update_weights_package(\n",
    "    weights_path=lora_adapter_loc,\n",
    "    target_filename=\"remote_lora_adapter_zipped\",\n",
    "    auto_delete_file=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4100384-b56c-4669-98c2-3b0d7353150e",
   "metadata": {},
   "outputs": [],
   "source": [
    "task.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d93ef86-65ed-471d-9d79-767b28f41e04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
